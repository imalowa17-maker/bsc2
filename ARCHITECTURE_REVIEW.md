import streamlit as stTURE REVIEW & GAP ANALYSIS
import osuary 8, 2026
import jsonll Dependenciesail
import pandas as pdount" in st.secrets:
from postmarker.core import PostmarkClientvice_account"])
from datetime import datetime, timedeltaet_dict.get('client_email')}")
import uuidelds (First Name, Last Name)
import base64upabaservice_account found in secrets")
import ioimport loggingleimport argparsee SQL Editor, run:import socketimport time# Supabase Importwards_submissions (from supabase import create_client    "Name" TEXT,# --- CONFIGURATION ---try:"Total Score" NUMERIC,    from dotenv import load_dotenv    load_dotenv()tion" TEXT,except Exception:re" NUMERIC,    passtomer Action" TEXT,    "Internal Business Processes Score" NUMERIC,# --- 1. SUPABASE CONNECTION (Replaces Google Sheets) ---@st.cache_resourceowth Score" NUMERIC,def get_supabase_client():ion" TEXT,    """Connect to Supabase. Cached to prevent reloading."""    try:es_JSON" TEXT,        url = st.secrets["supabase"]["url"]        key = st.secrets["supabase"]["key"]        return create_client(url, key)ULT '',    except Exception as e: DEFAULT '',        st.error(f"‚ö†Ô∏è Supabase Config Error: {e}")        return None" TEXT DEFAULT '',    "Lock Token" TEXT DEFAULT '',def get_postmark_token():FAULT '',    token = None" TEXT DEFAULT '',    try:ted_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()        token = st.secrets["postmark"]["token"]    except Exception:        token = os.getenv("POSTMARK_API_TOKEN")"Name");    if not token:timestamp ON md_awards_submissions("Timestamp");        # Fallback/Warning if missing        return None    return tokenSecretsdef score_perspective(action_text, files, keywords):    text = (action_text or "").lower()    if not text:        return 0.0    matches = 0ABASE_URL"    for kw in keywords:ON_KEY"        if kw.lower() in text:            matches += 1    keyword_points = min(matches, 5) / 5.0 * 15.0     length_points = min(len(text), 300) / 300.0 * 10.0    score = keyword_points + length_points    try:r_password = "YOUR_EVALUATOR_PASSWORD"        num_files = len(files) if files else 0    except Exception:        num_files = 0ervice account JSON here    if len(text) > 200 and num_files >= 2:        score = min(25.0, score + 3.0)    return round(min(25.0, score), 1)private_key = "-----BEGIN PRIVATE KEY-----\n...\n-----END PRIVATE KEY-----\n"def _evaluate_perspective(action_text, files):    pts = 0 "..."    text = (action_text or "").strip()m/o/oauth2/auth"    if text:"https://oauth2.googleapis.com/token"        pts += 109_cert_url = "https://www.googleapis.com/oauth2/v1/certs"    if len(text) > 150:"..."        pts += 10    try:        num_files = len(files) if files else 0    except Exception:        num_files = 0    if num_files >= 2:        pts += 5    return int(min(25, pts))- Submit a test entry as employee# Constantsevaluator to reviewTARGET_EMAIL = "busdev3@securico.co.zw"GDRIVE_HOLDER_ID = "1Ll1N63MviMMNH7zmYxwh2TqVSOTglXtg"CSV_LOG_PATH = "evaluator_records.csv"to secrets.toml)SUPABASE_TABLE = "md_awards_submissions"export SUPABASE_URL="your_url"bsc_structure = {EY="your_key"    "Financial": "Improve profitability and financial performance",    "Customer": "Enhance customer satisfaction and retention",    "Internal Business Processes": "Optimize operational efficiency and compliance",    "Learning & Growth": "Develop employee skills and organizational capacity"} Supabase table name is: `md_awards_submissions`- Google Drive folder ID: `1Ll1N63MviMMNH7zmYxwh2TqVSOTglXtg`st.set_page_config(page_title="MD AWARDS", page_icon="üèÜ", layout="wide")- CSV backup: `evaluator_records.csv`# --- 2. SUPABASE STORAGE (For File Uploads) ---def _is_network_error(e):    """Return True if exception looks like a network/DNS/temporary transport error."""    if isinstance(e, (OSError, socket.gaierror, ConnectionError)):        return Trueo Google Drive    return Falseications sent4. ‚úÖ Evaluator can log in5. ‚úÖ Data appears in Supabase dashboarddef upload_to_supabase(all_files_dict, first_name, last_name):    """Upload files to Supabase Storage in a uniquely named folder.    Args:        all_files_dict: dict mapping perspective -> list of Streamlit UploadedFile objects        first_name, last_name: strings for folder naming    Returns: (folder_url, files_meta)        - folder_url: URL to view files (Supabase project URL)        - files_meta: dict mapping perspective -> list of {name, path, publicUrl}    """    supabase = get_supabase_client()    if not supabase:        raise RuntimeError("Supabase client not available")    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")    folder_name = f"{first_name.strip()}_{last_name.strip()}_{timestamp}"        # Create a bucket name (ensure it exists in your Supabase project)    bucket_name = "md-awards-files"  # You'll need to create this bucket in Supabase        try:        files_meta = {}        for perspective, flist in (all_files_dict or {}).items():            files_meta[perspective] = []            if not flist:                continue            for up in flist:                try:                    # Create a unique path for each file                    file_path = f"{folder_name}/{perspective}/{up.name}"                                        # Upload file to Supabase Storage                    file_bytes = up.getvalue()                    response = supabase.storage.from_(bucket_name).upload(                        path=file_path,                        file=file_bytes,                        file_options={"content-type": up.type or "application/octet-stream"}                    )                                        # Get public URL for the file                    public_url = supabase.storage.from_(bucket_name).get_public_url(file_path)                                        files_meta[perspective].append({                        "name": up.name,                        "path": file_path,                        "publicUrl": public_url                    })                except Exception as e:                    st.warning(f"‚ö†Ô∏è Could not upload file {getattr(up, 'name', 'unknown')}: {e}")                # Return a general folder URL (you can customize this to your Supabase dashboard)        supabase_url = st.secrets["supabase"]["url"]        folder_url = f"{supabase_url}/storage/v1/object/public/{bucket_name}/{folder_name}"                return folder_url, files_meta    except Exception as e:        raise RuntimeError(f"Supabase upload failed: {e}")# --- 4. DATA LOGGING (Using Supabase) ---def log_submission(first_name, last_name, score_breakdown, actions_dict, folder_url, files_map=None):    """Append a submission record to the Supabase table.    Falls back to local CSV if Supabase is unavailable.    files_map should be a dict mapping perspective -> list of {name,id,webViewLink}    and will be serialized to JSON.    """    name = f"{first_name.strip()} {last_name.strip()}".strip()    timestamp = datetime.now().isoformat()    total_score = round(sum(score_breakdown.values()), 1)    files_json = json.dumps(files_map) if files_map else ""    record = {        "Name": name,        "Timestamp": timestamp,        "Total Score": total_score,        "Financial Score": score_breakdown.get("Financial", 0.0),        "Financial Action": actions_dict.get("Financial", ""),        "Customer Score": score_breakdown.get("Customer", 0.0),        "Customer Action": actions_dict.get("Customer", ""),        "Internal Business Processes Score": score_breakdown.get("Internal Business Processes", 0.0),        "Internal Business Processes Action": actions_dict.get("Internal Business Processes", ""),        "Learning & Growth Score": score_breakdown.get("Learning & Growth", 0.0),        "Learning & Growth Action": actions_dict.get("Learning & Growth", ""),        "Folder_URL": folder_url,        "Files_JSON": files_json,        "Evaluator Vote": "",        "Evaluator Comment": "",        "Stage 1 Recommendation": "",        "Stage 1 Comment": "",        "Committee Votes": "",        "Current Status": ""    }    try:        supabase = get_supabase_client()        if not supabase:            raise RuntimeError("Supabase client unavailable")                supabase.table(SUPABASE_TABLE).insert(record).execute()    except Exception as e:        st.error(f"‚ö†Ô∏è Could not write submission to Supabase: {e}")        # Fallback to local CSV to avoid data loss        try:            if os.path.exists(CSV_LOG_PATH):                df = pd.read_csv(CSV_LOG_PATH)                df = pd.concat([df, pd.DataFrame([record])], ignore_index=True)            else:                df = pd.DataFrame([record])            df.to_csv(CSV_LOG_PATH, index=False)        except Exception as e2:            st.error(f"‚ö†Ô∏è Could not write submission to backup CSV: {e2}")def read_records():    """Read submissions from the Supabase table and return as a DataFrame.    Falls back to local CSV if Supabase is unavailable.    """    try:        supabase = get_supabase_client()        if not supabase:            raise RuntimeError("Supabase client unavailable")                response = supabase.table(SUPABASE_TABLE).select("*").execute()        records = response.data        df = pd.DataFrame.from_records(records)        if df.empty:            return None        return df    except Exception as e:        st.error(f"‚ö†Ô∏è Error reading records from Supabase: {e}")        # Fallback to CSV        try:            if os.path.exists(CSV_LOG_PATH):                return pd.read_csv(CSV_LOG_PATH)            return None        except Exception as e2:            st.error(f"‚ö†Ô∏è Error reading local CSV: {e2}")            return None# --- 5. EVALUATOR UPDATE LOGIC (Using Supabase with Locking) ---def update_evaluator_vote(name, timestamp, vote=None, comment=None, lock_token=None, stage1_rec=None, stage1_comment=None, committee_vote=None, evaluator_name=None, current_status=None):    """Update evaluator-related fields for a submission.    Supports: Evaluator Vote, Evaluator Comment, Stage 1 Recommendation/Comment, Committee Votes (appends evaluator:name:vote), and Current Status.    Enforces lock when available. Tries Supabase first; falls back to local CSV.    Returns True on success, False on failure.    """    try:        supabase = get_supabase_client()        if not supabase:            raise RuntimeError("Supabase client unavailable")                # Find the record by name and timestamp        response = supabase.table(SUPABASE_TABLE).select("*").eq("Name", name).eq("Timestamp", timestamp).execute()                if not response.data:            # Try finding by name only (latest)            response = supabase.table(SUPABASE_TABLE).select("*").eq("Name", name).order("Timestamp", desc=True).limit(1).execute()            if not response.data:                raise RuntimeError("Could not locate submission row for candidate")                record = response.data[0]        record_id = record.get("id")                # Check Lock        current_lock_token = record.get("Lock Token") or ""        if current_lock_token:            if not lock_token or str(lock_token) != str(current_lock_token):                raise RuntimeError("Row is locked by another editor; acquire lock before updating")                # Build update dict        updates = {}        if vote is not None:            updates["Evaluator Vote"] = vote        if comment is not None:            updates["Evaluator Comment"] = comment        if stage1_rec is not None:            updates["Stage 1 Recommendation"] = stage1_rec        if stage1_comment is not None:            updates["Stage 1 Comment"] = stage1_comment        if current_status is not None:            updates["Current Status"] = current_status                if committee_vote is not None:            existing = record.get("Committee Votes") or ""            new_entry = f"{evaluator_name or 'Evaluator'}:{committee_vote}"            updates["Committee Votes"] = existing + (";" if existing else "") + new_entry                # Clear lock if provided        if lock_token:            updates["Lock Token"] = ""            updates["Lock Expiry"] = ""                # Apply updates        supabase.table(SUPABASE_TABLE).update(updates).eq("id", record_id).execute()        return True            except Exception as e:        st.error(f"‚ö†Ô∏è Could not update Supabase: {e}")        # Fallback to CSV        try:            if os.path.exists(CSV_LOG_PATH):                df = pd.read_csv(CSV_LOG_PATH)                # Ensure columns exist                for c in ["Evaluator Vote", "Evaluator Comment", "Lock Token", "Lock Expiry", "Stage 1 Recommendation", "Stage 1 Comment", "Committee Votes", "Current Status"]:                    if c not in df.columns:                        df[c] = ""                mask = df["Name"] == name                if timestamp and "Timestamp" in df.columns:                    mask = mask & (df["Timestamp"] == timestamp)                # If locked, verify                if "Lock Token" in df.columns and mask.any():                    current = df.loc[mask, "Lock Token"].astype(str).iloc[0]                    if current and (not lock_token or str(lock_token) != str(current)):                        raise RuntimeError("Row is locked by another editor; acquire lock before updating")                if not mask.any():                    idx = df[df["Name"] == name].last_valid_index()                    if idx is None:                        raise RuntimeError("No matching record in CSV to update")                else:                    idx = df[mask].index[0]                # Apply updates to CSV row                if vote is not None:                    df.at[idx, "Evaluator Vote"] = vote                if comment is not None:                    df.at[idx, "Evaluator Comment"] = comment                if stage1_rec is not None:                    df.at[idx, "Stage 1 Recommendation"] = stage1_rec                if stage1_comment is not None:                    df.at[idx, "Stage 1 Comment"] = stage1_comment                if committee_vote is not None:                    existing = str(df.at[idx, "Committee Votes"] or "")                    new_entry = f"{evaluator_name or 'Evaluator'}:{committee_vote}"                    updated = existing + (";" if existing else "") + new_entry                    df.at[idx, "Committee Votes"] = updated                if current_status is not None:                    df.at[idx, "Current Status"] = current_status                # clear locks if provided                if lock_token:                    df.at[idx, "Lock Token"] = ""                    df.at[idx, "Lock Expiry"] = ""                df.to_csv(CSV_LOG_PATH, index=False)                return True        except Exception as e2:            st.error(f"‚ö†Ô∏è Could not write vote to backup CSV: {e2}")        return Falsedef acquire_lock(name, timestamp, holder="Evaluator", timeout_seconds=120):    """Attempt to acquire an edit lock for a submission row.    Returns (token, expiry_iso) on success, (None, None) on failure.    """    try:        supabase = get_supabase_client()        if not supabase:            raise RuntimeError("Supabase client unavailable")                # Find record        response = supabase.table(SUPABASE_TABLE).select("*").eq("Name", name).eq("Timestamp", timestamp).execute()                if not response.data:            # fallback to latest by name            response = supabase.table(SUPABASE_TABLE).select("*").eq("Name", name).order("Timestamp", desc=True).limit(1).execute()            if not response.data:                raise RuntimeError("Could not locate submission row for candidate")                record = response.data[0]        record_id = record.get("id")                # Check current lock        current_token = record.get("Lock Token") or ""        current_expiry = record.get("Lock Expiry") or ""        if current_token:            try:                exp = datetime.fromisoformat(current_expiry)                if exp > datetime.utcnow():                    st.error("Row is currently locked by another evaluator.")                    return None, None            except Exception:                st.error("Row appears locked; try again later or contact an admin.")                return None, None        token = str(uuid.uuid4())        expiry_dt = datetime.utcnow() + timedelta(seconds=timeout_seconds)        expiry_iso = expiry_dt.isoformat()        supabase.table(SUPABASE_TABLE).update({            "Lock Token": token,            "Lock Expiry": expiry_iso,            "Lock Holder": holder        }).eq("id", record_id).execute()        return token, expiry_iso    except Exception as e:        st.error(f"‚ö†Ô∏è Could not acquire lock: {e}")        # CSV fallback        try:            if os.path.exists(CSV_LOG_PATH):                df = pd.read_csv(CSV_LOG_PATH)                if "Lock Token" not in df.columns:                    df["Lock Token"] = ""                if "Lock Expiry" not in df.columns:                    df["Lock Expiry"] = ""                if "Lock Holder" not in df.columns:                    df["Lock Holder"] = ""                mask = df["Name"] == name                if timestamp and "Timestamp" in df.columns:                    mask = mask & (df["Timestamp"] == timestamp)                if mask.any():                    idx = df[mask].index[0]                    current_token = str(df.at[idx, "Lock Token"]) or ""                    current_expiry = str(df.at[idx, "Lock Expiry"]) or ""                    if current_token:                        try:                            exp = datetime.fromisoformat(current_expiry)                            if exp > datetime.utcnow():                                st.error("Row is currently locked by another evaluator.")                                return None, None                        except Exception:                            st.error("Row appears locked; try again later or contact an admin.")                            return None, None                    token = str(uuid.uuid4())                    expiry_dt = datetime.utcnow() + timedelta(seconds=timeout_seconds)                    expiry_iso = expiry_dt.isoformat()                    df.at[idx, "Lock Token"] = token                    df.at[idx, "Lock Expiry"] = expiry_iso                    df.at[idx, "Lock Holder"] = holder                    df.to_csv(CSV_LOG_PATH, index=False)                    return token, expiry_iso        except Exception as e2:            st.error(f"‚ö†Ô∏è Could not acquire lock in CSV fallback: {e2}")        return None, Nonedef release_lock(name, timestamp, token):    """Release an edit lock if token matches. Returns True on success."""    try:        supabase = get_supabase_client()        if not supabase:            raise RuntimeError("Supabase client unavailable")                response = supabase.table(SUPABASE_TABLE).select("*").eq("Name", name).eq("Timestamp", timestamp).execute()                if not response.data:            # fallback to latest by name            response = supabase.table(SUPABASE_TABLE).select("*").eq("Name", name).order("Timestamp", desc=True).limit(1).execute()            if not response.data:                raise RuntimeError("Could not locate submission row for candidate")                record = response.data[0]        record_id = record.get("id")                current = record.get("Lock Token") or ""        if not current or str(current) != str(token):            st.error("Cannot release lock: token does not match current lock")            return False        supabase.table(SUPABASE_TABLE).update({            "Lock Token": "",            "Lock Expiry": ""        }).eq("id", record_id).execute()        return True    except Exception as e:        st.error(f"‚ö†Ô∏è Could not release lock on Supabase: {e}")        # CSV fallback        try:            if os.path.exists(CSV_LOG_PATH):                df = pd.read_csv(CSV_LOG_PATH)                if "Lock Token" not in df.columns:                    return False                mask = df["Name"] == name                if timestamp and "Timestamp" in df.columns:                    mask = mask & (df["Timestamp"] == timestamp)                if not mask.any():                    idx = df[df["Name"] == name].last_valid_index()                    if idx is None:                        return False                else:                    idx = df[mask].index[0]                current = str(df.at[idx, "Lock Token"]) or ""                if not current or str(current) != str(token):                    st.error("Cannot release lock: token does not match current lock in CSV")                    return False                df.at[idx, "Lock Token"] = ""                df.at[idx, "Lock Expiry"] = ""                df.to_csv(CSV_LOG_PATH, index=False)                return True        except Exception as e2:            st.error(f"‚ö†Ô∏è Could not release lock in CSV fallback: {e2}")        return False# --- UI IMPLEMENTATION ---st.set_page_config(page_title="MD AWARDS", page_icon="üèÜ", layout="wide")with st.sidebar:    # LOGO LOGIC    script_dir = os.path.dirname(__file__)    logo_path = None    for fname in ["LOGO WHITE PNG.png", "LOGO WHITE PNG"]:        p = os.path.join(script_dir, fname)        if os.path.exists(p):            logo_path = p            break    if not logo_path:        try:            for f in os.listdir(script_dir):                if os.path.splitext(f)[0].lower() == "logo white png":                    logo_path = os.path.join(script_dir, f)                    break        except Exception:            logo_path = None    if logo_path and os.path.exists(logo_path):        st.markdown(            """            <style>            div[data-testid="stSidebar"] img {                background-color: #111 !important;                padding: 8px;                border-radius: 6px;                display: block;                margin-left: auto;                margin-right: auto;            }            </style>            """,            unsafe_allow_html=True        )        st.image(logo_path, use_container_width=True)    else:        st.markdown("# üèÜ MD AWARDS")    st.markdown("# üí° Winning Tips")    st.info("""    **To reach 'Extra Mile' status:**    * üìù Write detailed descriptions (>100 chars).    * üìé Attach 2+ files per perspective.    * üéØ Align actions with the listed Goal.    """)    st.divider()    st.caption("Business Development 2026")    st.divider()        st.markdown("# üîê Evaluator Access")    eval_pwd = st.text_input("Evaluator Password", type="password", help="Enter evaluator password to access workspace")    try:        is_evaluator = bool(eval_pwd and eval_pwd == st.secrets["auth"]["evaluator_password"])    except Exception:        is_evaluator = Falsest.title("üèÜ MD'S Quality & Excellence Awards")st.markdown("---")if is_evaluator:    st.header("Evaluator Workspace")    tab1, tab2, tab3 = st.tabs(["Summary Table", "Detailed Review", "Final Results"])    df = read_records()    with tab1:        if df is None or df.empty:            st.info("Informing: No submissions found yet.")        else:            # Mark the latest submission with an indicator            display_df = df.copy()            # Ensure proper datetime parsing for robust sorting            display_df["Date_parsed"] = pd.to_datetime(display_df["Timestamp"], errors="coerce")            display_df = display_df.sort_values("Date_parsed", ascending=False)            if not display_df.empty:                latest = display_df.iloc[0]                display_df["Latest"] = ""                display_df.loc[display_df.index[0], "Latest"] = "üèÖ"                st.caption(f"Latest submission: {latest['Name']} ‚Äî {latest['Timestamp']}")                st.dataframe(display_df[["Latest", "Name", "Timestamp", "Total Score", "Current Status"]])    with tab2:        if df is None or df.empty:            st.info("Informing: No submissions found yet.")        else:            names = df["Name"].unique().tolist()            selected = st.selectbox("Select Candidate", names)            if selected:                rec = df[df["Name"] == selected].sort_values("Timestamp", ascending=False).iloc[0]                st.subheader(f"Review: {selected}")                # --- Scores & Metrics ---                def _num(x):                    try:                        return float(x)                    except Exception:                        return 0.0                fin_score = _num(rec.get("Financial Score", 0))                cust_score = _num(rec.get("Customer Score", 0))                ibp_score = _num(rec.get("Internal Business Processes Score", 0))                lg_score = _num(rec.get("Learning & Growth Score", 0))                total_score = _num(rec.get("Total Score", fin_score + cust_score + ibp_score + lg_score))                cols = st.columns(5)                cols[0].metric("Total Score", f"{total_score:.1f}/100")                cols[1].metric("Financial", f"{fin_score:.1f}/25")                cols[2].metric("Customer", f"{cust_score:.1f}/25")                cols[3].metric("Internal BP", f"{ibp_score:.1f}/25")                cols[4].metric("Learning & Growth", f"{lg_score:.1f}/25")                st.write("**Action Taken (Full Text)**")                st.write(f"**Financial ({fin_score:.1f}/25):** {rec.get('Financial Action', '')}")                st.write(f"**Customer ({cust_score:.1f}/25):** {rec.get('Customer Action', '')}")                st.write(f"**Internal Business Processes ({ibp_score:.1f}/25):** {rec.get('Internal Business Processes Action', '')}")                st.write(f"**Learning & Growth ({lg_score:.1f}/25):** {rec.get('Learning & Growth Action', '')}")                # Show per-perspective uploaded files (if any) with preview links                files_json_raw = rec.get('Files_JSON') or rec.get('Files') or ""                files_by_persp = {}                if files_json_raw and not pd.isna(files_json_raw):                    try:                        if isinstance(files_json_raw, str):                            files_by_persp = json.loads(files_json_raw)                        else:                            files_by_persp = files_json_raw                    except Exception:                        files_by_persp = {}                # Determine folder URL                raw_folder = rec.get('Folder_URL') or ""                is_folder_blank = pd.isna(raw_folder) or str(raw_folder).strip() == "" or str(raw_folder).strip().lower() == "nan"                is_folder_fallback_msg = isinstance(raw_folder, str) and 'check email for attachments' in raw_folder.lower()                st.divider()                st.markdown("**Uploaded Evidence by Perspective**")                left_col, right_col = st.columns([4, 6])                                with left_col:                    if not is_folder_blank and not is_folder_fallback_msg:                        if files_by_persp:                            for p in bsc_structure.keys():                                flist = files_by_persp.get(p) or []                                if not flist:                                    continue                                st.markdown(f"**{p}:**")                                for i, fmeta in enumerate(flist):                                    name = fmeta.get('name') or fmeta.get('Name') or ''                                    preview = fmeta.get('webViewLink') or (fmeta.get('id') and f"https://drive.google.com/file/d/{fmeta.get('id')}/preview") or ''                                    rcols = st.columns([6, 1])                                    rcols[0].write(name)                                    if preview:                                        btn_key = f"preview_btn_{selected}_{p}_{i}"                                        if rcols[1].button("üëÅÔ∏è Preview", key=btn_key):                                            st.session_state[f"preview_url_{selected}"] = preview                                            st.session_state[f"preview_name_{selected}"] = name                        else:                            st.info('No files are listed for this candidate in the record. Use the folder button to inspect uploads in Drive if any exist.')                                                folder_url = str(raw_folder).strip()                        if isinstance(folder_url, str) and 'Upload Error' in folder_url:                            st.warning('Files were successfully sent via email, but a temporary network error prevented them from being saved to the Cloud Folder. Please check the submission email attachments.')                                                try:                            st.link_button("üìÇ Open Candidate Evidence", url=folder_url, use_container_width=True)                        except Exception:                            st.markdown(f"[üìÇ Open Candidate Evidence]({folder_url})")                    elif is_folder_blank or is_folder_fallback_msg:                        if not files_by_persp:                            st.info('‚ÑπÔ∏è No digital evidence was uploaded by this candidate.')                        else:                            for p in bsc_structure.keys():                                flist = files_by_persp.get(p) or []                                if not flist:                                    continue                                st.markdown(f"**{p}:**")                                for i, fmeta in enumerate(flist):                                    name = fmeta.get('name') or fmeta.get('Name') or ''                                    preview = fmeta.get('webViewLink') or (fmeta.get('id') and f"https://drive.google.com/file/d/{fmeta.get('id')}/preview") or ''                                    rcols = st.columns([6, 1])                                    rcols[0].write(name)                                    if preview:                                        btn_key = f"preview_btn_{selected}_{p}_{i}"                                        if rcols[1].button("üëÅÔ∏è Preview", key=btn_key):                                            st.session_state[f"preview_url_{selected}"] = preview                                            st.session_state[f"preview_name_{selected}"] = name                                with right_col:                    preview_key = f"preview_url_{selected}"                    if preview_key in st.session_state and st.session_state.get(preview_key):                        st.markdown(f"**Preview: {st.session_state.get(f'preview_name_{selected}', '')}**")                        try:                            st.components.v1.iframe(st.session_state[preview_key], height=700)                        except Exception as e:                            st.error(f"‚ö†Ô∏è Could not render preview iframe: {e}")                        if st.button("Close Preview", key=f"close_preview_{selected}"):                            try:                                del st.session_state[preview_key]                            except Exception:                                pass                            name_key = f"preview_name_{selected}"                            if name_key in st.session_state:                                try:                                    del st.session_state[name_key]                                except Exception:                                    pass                    else:                        st.info("Select a file to preview from the list on the left.")                st.divider()                st.subheader("Evaluator Vote & Comment")                lock_key = f"lock_token_{selected}"                timestamp = rec.get("Timestamp")                locked_token = st.session_state.get(lock_key)                if locked_token:                    st.info("üîí You have the edit lock.")                    if st.button("Release Lock", key=f"rel_{selected}"):                        release_lock(selected, timestamp, locked_token)                        del st.session_state[lock_key]                        st.rerun()                else:                    if st.button("Acquire Edit Lock", key=f"acq_{selected}"):                        tok, exp = acquire_lock(selected, timestamp)                        if tok:                            st.session_state[lock_key] = tok                            st.rerun()                # Form fields                disabled = (locked_token is None)                        # Stage 1            st.markdown("#### Stage 1")            rec_choice = st.radio("Recommendation", ["", "Recommend for Finals", "Reject"], key=f"s1_{selected}", disabled=disabled)            rec_comment = st.text_area("Stage 1 Comment", key=f"c1_{selected}", disabled=disabled)                        if st.button("Submit Stage 1", disabled=disabled):                update_evaluator_vote(selected, timestamp, lock_token=locked_token, stage1_rec=rec_choice, stage1_comment=rec_comment, current_status="Stage 1 Complete")                st.success("Saved!")                release_lock(selected, timestamp, locked_token)                del st.session_state[lock_key]            # Stage 2            st.markdown("#### Stage 2 (Committee)")            comm_vote = st.selectbox("Vote", ["", "Winner", "Runner-up", "Reject"], key=f"s2_{selected}", disabled=disabled)            eval_name = st.text_input("Evaluator Name", key=f"en_{selected}", disabled=disabled)                        if st.button("Submit Committee Vote", disabled=disabled):                if eval_name:                    update_evaluator_vote(selected, timestamp, lock_token=locked_token, committee_vote=comm_vote, evaluator_name=eval_name, current_status="Stage 2 In Progress")                    st.success("Vote Recorded!")                    release_lock(selected, timestamp, locked_token)                    del st.session_state[lock_key]                else:                    st.error("Name required.")    # --- Final Results tab ---    with tab3:        st.subheader("Final Results ‚Äî Recommended Candidates")        if df is None or df.empty:            st.info("No submissions found yet.")        else:            df_view = df.copy()            if "Stage 1 Recommendation" in df_view.columns:                mask = df_view["Stage 1 Recommendation"].fillna("").str.lower().str.contains("recommend")            else:                mask = pd.Series([False] * len(df_view))            recs = df_view[mask]            if recs.empty:                st.info("No candidates have been recommended for finals yet.")            else:                def vote_to_weight(v):                    v = str(v or "").strip().lower()                    if "winner" in v:                        return 1.0                    if "runner" in v:                        return 0.7                    if "shortlist" in v:                        return 0.5                    return 0.0                rows = []                for _, r in recs.iterrows():                    name = r.get("Name")                    sys_score = None                    for key in ("Total Score",):                        try:                            sys_score = float(r.get(key))                            break                        except Exception:                            sys_score = None                    if sys_score is None:                        try:                            sys_score = sum([float(r.get("Financial Score", 0)), float(r.get("Customer Score", 0)), float(r.get("Internal Business Processes Score", 0)), float(r.get("Learning & Growth Score", 0))])                        except Exception:                            sys_score = 0.0                    committee = str(r.get("Committee Votes", "") or "")                    weights = []                    if committee:                        for part in committee.split(";"):                            if ":" in part:                                _, v = part.split(":", 1)                            else:                                v = part                            weights.append(vote_to_weight(v))                    else:                        if r.get("Evaluator Vote"):                            weights.append(vote_to_weight(r.get("Evaluator Vote")))                    avg_w = float(sum(weights) / len(weights)) if weights else 0.0                    final_rank = sys_score * 0.4 + (avg_w * 100) * 0.6                    rows.append({"Name": name, "Total Score": sys_score, "Committee Votes": committee, "Avg Vote Weight": round(avg_w, 2), "Final Rank": round(final_rank, 1), "Current Status": r.get("Current Status", "")})                result_df = pd.DataFrame(rows).sort_values("Final Rank", ascending=False)                st.dataframe(result_df)                if not result_df.empty:                    top = result_df.iloc[0]                    st.metric("Top Candidate", top["Name"], delta=f"Score: {top['Final Rank']}")                    csv = result_df.to_csv(index=False)                    st.download_button("üì• Export Results", csv, "awards_results.csv")else:    # --- EMPLOYEE FORM ---    col_a, col_b = st.columns(2)    first_name = col_a.text_input("First Name")    last_name = col_b.text_input("Surname")        st.write("### üìä Submission Strength Dashboard")    st.columns(4) # Placeholders    with st.form("bsc_form"):        user_data = {}        for p, goal in bsc_structure.items():            st.subheader(f"üîπ {p} Perspective")            st.markdown(f"**Strategic Goal:** `{goal}`")            c1, c2 = st.columns([2, 1])            act = c1.text_area("Action Taken", key=f"txt_{p}")            fils = c2.file_uploader("Evidence", accept_multiple_files=True, key=f"f_{p}")            user_data[p] = {"action": act, "files": fils}            st.divider()                submit = st.form_submit_button("üöÄ Submit Final Performance for Evaluation")    if submit:        if not first_name or not last_name:            st.error("‚ö†Ô∏è Identity Required.")        else:            try:                token = get_postmark_token()            except RuntimeError as e:                st.error(f"‚ö†Ô∏è System Config Error: {e}")            else:                # Compute scores for each perspective                score_breakdown = {}                all_files = []                for p, data in user_data.items():                    action_text = (data.get("action") or "").strip()                    files = data.get("files") or []                    score = _evaluate_perspective(action_text, files)                    score_breakdown[p] = int(score)                    # collect files                    if files:                        for file in files:                            all_files.append(file)                total_score = sum(score_breakdown.values())                # Build email body including the score breakdown                breakdown_lines = "\n".join([f"{p}: {int(score)}/25%" for p, score in score_breakdown.items()])                email_body = f"""                MD'S Quality & Excellence Awards Submission                Name: {first_name} {last_name}                ---                Score Breakdown (per perspective):                {breakdown_lines}                Total Score: {int(total_score)}/100%                """                # --- POSTMARK EMAIL LOGIC ---                try:                    status = st.empty()                    status.info("Finalizing submission...")                    client = PostmarkClient(server_token=token)                    # Build a per-perspective files dict and upload to Supabase                    all_files_dict = {p: (user_data[p].get("files") or []) for p in user_data}                    try:                        folder_url, uploaded_files_meta = upload_to_supabase(all_files_dict, first_name, last_name)                    except Exception as e:                        logging.exception("Supabase upload failed")                        # If it's a network/DNS/connection issue, mark for manual review and continue                        if _is_network_error(e) or isinstance(e, (ConnectionError, OSError, socket.gaierror)):                            folder_url = 'Manual Review Required (Upload Error)'                            uploaded_files_meta = {}                            st.warning('Files were successfully sent via email, but a temporary network error prevented them from being saved to the Cloud Storage.')                        else:                            st.warning(f"‚ö†Ô∏è Could not upload to Supabase Storage: {e}")                            folder_url = "Check Email for Attachments"                            uploaded_files_meta = {}                                        # Append a simple listing of uploaded files to the email body for easy access                    if uploaded_files_meta:                        email_body += "\n\nEvidence Files:\n"                        for p, flist in uploaded_files_meta.items():                            if flist:                                email_body += f"\n{p}:\n"                                for f in flist:                                    link = f.get('webViewLink') or (f.get('id') and f"https://drive.google.com/file/d/{f.get('id')}/view")                                    email_body += f"- {f.get('name')}: {link}\n"                    # Convert Streamlit UploadedFile objects into Postmark-friendly dicts                    pm_attachments = []                    for pfiles in all_files_dict.values():                        for up in pfiles:                            raw = up.getvalue()  # bytes                            pm_attachments.append({                                "Name": up.name,                                "Content": base64.b64encode(raw).decode("ascii"),                                "ContentType": up.type or "application/octet-stream"                            })                    # Check if user already submitted                    existing = supabase.table(SUPABASE_TABLE).select("*").eq("Name", f"{first_name} {last_name}").execute()                    if existing.data:                        st.error("You've already submitted. Contact admin for updates.")                        st.stop()                    # Send Email (attachments optional)                    response = client.emails.send(                        From=TARGET_EMAIL,                        To=f"{first_name}.{last_name}@company.com",                        Subject="Submission Received - MD Awards",                        HtmlBody=f"Thank you {first_name}! Your submission has been received..."                    )                    # Log submission (includes folder URL and per-perspective files JSON)                    actions_only = {p: (user_data[p]["action"] or "") for p in user_data}                    log_submission(first_name, last_name, score_breakdown, actions_only, folder_url, files_map=uploaded_files_meta)                    status.success("‚úÖ Finalizing submission...")                except Exception as e:
                    st.error(f"‚ö†Ô∏è Error in submission: {str(e)}")
- ‚úÖ Email notifications via Postmark
- ‚úÖ AUTOMATIC SCORING (0-100 points)
SUBMISSION_DEADLINE = datetime(2026, 2, 1)
if datetime.now() > SUBMISSION_DEADLINE:
    st.error("Submissions are closed.") 100)
    st.stop()t entered
- 10 pts: Text >150 characters
- 5 pts: 2+ files uploaded

### 2. EVALUATOR ACCESS ‚úÖ COMPLETE
- ‚úÖ Password protection
- ‚úÖ Secure dashboard with 3 tabs
- ‚úÖ Submission metadata (Name, Timestamp, Scores)
- ‚úÖ File preview with Supabase links
- ‚úÖ Latest submission indicator

### 3. MULTI-STAGE WORKFLOW ‚úÖ COMPLETE
**Stage 1: Lead Evaluator**
- ‚úÖ Recommend/Reject radio buttons
- ‚úÖ Comment fields
- ‚úÖ Status tracking ("Stage 1 Complete")

**Stage 2: Committee Panel**
- ‚úÖ Vote options (Winner/Runner-up/Reject)
- ‚úÖ Multiple evaluator support
- ‚úÖ Vote tracking with names
- ‚úÖ Status updates ("Stage 2 In Progress")

**Locking System:**
- ‚úÖ UUID-based edit locks
- ‚úÖ 120-second timeout
- ‚úÖ Concurrent edit prevention

### 4. AUTOMATED WINNER CALCULATION ‚úÖ COMPLETE
**Formula:**
- Final Rank = (System Score √ó 40%) + (Avg Vote Weight √ó 100 √ó 60%)
- Vote weights: Winner=1.0, Runner-up=0.7, Shortlist=0.5
- ‚úÖ Automatic sorting and winner declaration

---

## ‚ö†Ô∏è CRITICAL GAPS

### 1. ‚ùå ANTI-DUPLICATE LOGIC
**Risk:** Users can submit multiple times
**Impact:** Score inflation, system gaming
**Priority:** HIGH

### 2. ‚ùå AUDIT LOGS
**Risk:** No accountability for evaluator actions
**Impact:** Cannot track vote changes/manipulation
**Priority:** HIGH

### 3. ‚ö†Ô∏è PARTIAL EMAIL NOTIFICATIONS
**Gap:** Candidates don't receive confirmation emails
**Impact:** Poor user experience
**Priority:** MEDIUM

### 4. ‚ö†Ô∏è SCORING RUBRIC VISIBILITY
**Gap:** Users don't see live score preview
**Impact:** Reduced transparency
**Priority:** MEDIUM

### 5. ‚ùå SUBMISSION DEADLINE
**Risk:** Late submissions after evaluation starts
**Impact:** Unfair advantage
**Priority:** HIGH

### 6. ‚ùå DATA EXPORT
**Gap:** No CSV/Excel export for results
**Impact:** Manual report generation
**Priority:** MEDIUM

### 7. ‚ö†Ô∏è FILE TYPE VALIDATION
**Risk:** Accepts any file type
**Impact:** Security/abuse risk
**Priority:** HIGH

### 8. ‚ö†Ô∏è STAGE PROGRESSION CONTROL
**Gap:** Manual stage tracking
**Impact:** Workflow confusion
**Priority:** MEDIUM

### 9. ‚ùå ANONYMIZATION OPTION
**Gap:** Evaluators see names (potential bias)
**Impact:** Fairness concerns
**Priority:** LOW

### 10. ‚ö†Ô∏è MAX SCORE DISPLAY
**Gap:** Not prominent during submission
**Impact:** User confusion
**Priority:** LOW

---

## üìä SCORING BREAKDOWN

| Perspective | Max Points | Criteria |
|------------|-----------|----------|
| Financial | 25 | Text(10) + Length>150(10) + 2+Files(5) |
| Customer | 25 | Text(10) + Length>150(10) + 2+Files(5) |
| Internal BP | 25 | Text(10) + Length>150(10) + 2+Files(5) |
| Learning & Growth | 25 | Text(10) + Length>150(10) + 2+Files(5) |
| **TOTAL** | **100** | **Automated** |

**Final Ranking:**
- System Score Weight: 40%
- Committee Votes Weight: 60%

---

## üéØ RECOMMENDED IMPLEMENTATION ORDER

1. **Anti-duplicate logic** (prevents gaming)
2. **Submission deadline** (enforces fairness)
3. **File type validation** (security)
4. **Audit logs** (accountability)
5. **Candidate email confirmations** (UX)
6. **Data export** (reporting)
7. **Live score preview** (transparency)
8. **Stage progression automation** (workflow)
9. **Anonymization** (bias reduction)
10. **Score display enhancement** (clarity)

---

## ‚úÖ CONCLUSION

**Core Workflow:** ‚úÖ FULLY FUNCTIONAL
- Public submission ‚úÖ
- Secure evaluator access ‚úÖ
- Two-stage evaluation ‚úÖ
- Automated winner calculation ‚úÖ

**Production Readiness:** ‚ö†Ô∏è 70%
- Missing critical safeguards (duplicates, deadlines, validation)
- Lacks audit trail
- Needs UX improvements

**Overall Assessment:** The system supports the complete award workflow but requires security and governance enhancements before production deployment.

ALLOWED_TYPES = ["pdf", "docx", "jpg", "png", "xlsx"]
if not any(up.name.endswith(t) for t in ALLOWED_TYPES):
    st.error(f"Only {ALLOWED_TYPES} files allowed")
